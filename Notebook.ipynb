{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7764110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\flatbuffers\\compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  'hamming': pil_image.HAMMING,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  'box': pil_image.BOX,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': pil_image.LANCZOS,\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593313f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  3\n",
      "Size of Action Space ->  1\n",
      "Max Value of Action ->  2.0\n",
      "Min Value of Action ->  -2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "problem = \"Pendulum-v1\"\n",
    "env = gym.make(problem)\n",
    "\n",
    "# This is needed to get the input size for the NN\n",
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "# This is needed to clip the actions within the legal boundaries\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a25ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a noise used in the paper that introduced DDPG https://arxiv.org/pdf/1509.02971v6.pdf\n",
    "# From what I understand, we can also use Gaussian or other noise without much difference,\n",
    "# I left the noise as is\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493ba423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Its important to make sure we only sample from used buffer space\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "\n",
    "    # Makes a record of the outputted (s,a,r,s') obervation tuple\n",
    "    def record(self, obs_tuple):\n",
    "        # Reuse the same buffer replacing old entries\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "\n",
    "    @tf.function\n",
    "    def update(\n",
    "        self, state_batch, action_batch, reward_batch, next_state_batch,\n",
    "    ):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(next_state_batch, training=True)\n",
    "            y = reward_batch + gamma * target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_model(state_batch, training=True)\n",
    "            critic_value = critic_model([state_batch, actions], training=True)\n",
    "\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Sample only valid data\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size, replace=False)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
    "\n",
    "\n",
    "# This updates the weights in a slow manner which keeps stability\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f235a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(layer1=400, layer2=300):\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(inputs)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    # Multiply to fill the whole action space which should be equal around 0\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_critic(layer1=400, layer2=300):\n",
    "    # State as input\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(concat)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    # Make it into a keras model\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c76273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object, use_noise=True):\n",
    "    # For doing actions without added noise\n",
    "    if not use_noise:     \n",
    "        sampled_actions = tf.squeeze(actor_model(state)).numpy()\n",
    "        legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "        \n",
    "        return [np.squeeze(legal_action)]\n",
    "    else:\n",
    "        sampled_actions = tf.squeeze(actor_model(state))\n",
    "        noise = noise_object()\n",
    "        # Adding noise to action\n",
    "        sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "        # We make sure action is within bounds\n",
    "        legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "        return [np.squeeze(legal_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d09a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2\n",
    "ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "\n",
    "# Learning rate for actor-critic models\n",
    "critic_lr = 0.002\n",
    "actor_lr = 0.001\n",
    "\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 100\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "# Used to update target networks\n",
    "tau = 0.005\n",
    "\n",
    "buffer = Buffer(50000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11542df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b89a8efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Avg Reward is ==> -1166.5130268429475\n",
      "Episode * 1 * Avg Reward is ==> -1536.6956840485027\n",
      "Episode * 2 * Avg Reward is ==> -1622.1710168627903\n",
      "Episode * 3 * Avg Reward is ==> -1403.238325833018\n",
      "Episode * 4 * Avg Reward is ==> -1367.408433234064\n",
      "Episode * 5 * Avg Reward is ==> -1336.0829827288524\n",
      "Episode * 6 * Avg Reward is ==> -1345.2592406806505\n",
      "Episode * 7 * Avg Reward is ==> -1297.7536799739742\n",
      "Episode * 8 * Avg Reward is ==> -1355.462054857927\n",
      "Episode * 9 * Avg Reward is ==> -1327.0558127338393\n",
      "Episode * 10 * Avg Reward is ==> -1303.5025077636994\n",
      "Episode * 11 * Avg Reward is ==> -1347.4529934104892\n",
      "Episode * 12 * Avg Reward is ==> -1350.096877243016\n",
      "Episode * 13 * Avg Reward is ==> -1314.908664968503\n",
      "Episode * 14 * Avg Reward is ==> -1338.816691791041\n",
      "Episode * 15 * Avg Reward is ==> -1346.6339549447757\n",
      "Episode * 16 * Avg Reward is ==> -1361.3416533548766\n",
      "Episode * 17 * Avg Reward is ==> -1362.0522768016235\n",
      "Episode * 18 * Avg Reward is ==> -1359.307785384177\n",
      "Episode * 19 * Avg Reward is ==> -1352.8130472322068\n",
      "Episode * 20 * Avg Reward is ==> -1374.2724875496797\n",
      "Episode * 21 * Avg Reward is ==> -1366.3092658471385\n",
      "Episode * 22 * Avg Reward is ==> -1354.3386669198146\n",
      "Episode * 23 * Avg Reward is ==> -1376.0125673697373\n",
      "Episode * 24 * Avg Reward is ==> -1357.264846012551\n",
      "Episode * 25 * Avg Reward is ==> -1341.2578908902897\n",
      "Episode * 26 * Avg Reward is ==> -1334.0054415227235\n",
      "Episode * 27 * Avg Reward is ==> -1343.5869726728874\n",
      "Episode * 28 * Avg Reward is ==> -1334.209256974257\n",
      "Episode * 29 * Avg Reward is ==> -1325.3978838952266\n",
      "Episode * 30 * Avg Reward is ==> -1315.920516924807\n",
      "Episode * 31 * Avg Reward is ==> -1316.742338046774\n",
      "Episode * 32 * Avg Reward is ==> -1330.377801496111\n",
      "Episode * 33 * Avg Reward is ==> -1318.5607470274376\n",
      "Episode * 34 * Avg Reward is ==> -1314.6049530501737\n",
      "Episode * 35 * Avg Reward is ==> -1321.2081281246335\n",
      "Episode * 36 * Avg Reward is ==> -1318.3840253704977\n",
      "Episode * 37 * Avg Reward is ==> -1310.8330384660642\n",
      "Episode * 38 * Avg Reward is ==> -1312.6167881356434\n",
      "Episode * 39 * Avg Reward is ==> -1310.076462523361\n",
      "Episode * 40 * Avg Reward is ==> -1311.7868351432687\n",
      "Episode * 41 * Avg Reward is ==> -1283.1696347280367\n",
      "Episode * 42 * Avg Reward is ==> -1274.779383402091\n",
      "Episode * 43 * Avg Reward is ==> -1287.5712152368699\n",
      "Episode * 44 * Avg Reward is ==> -1292.1637178758017\n",
      "Episode * 45 * Avg Reward is ==> -1289.7674797561508\n",
      "Episode * 46 * Avg Reward is ==> -1284.6260767214567\n",
      "Episode * 47 * Avg Reward is ==> -1278.9482751314815\n",
      "Episode * 48 * Avg Reward is ==> -1255.3362938292205\n",
      "Episode * 49 * Avg Reward is ==> -1255.012828650369\n",
      "Episode * 50 * Avg Reward is ==> -1259.5551892834894\n",
      "Episode * 51 * Avg Reward is ==> -1242.2467566886812\n",
      "Episode * 52 * Avg Reward is ==> -1237.274785641725\n",
      "Episode * 53 * Avg Reward is ==> -1252.3925118662416\n",
      "Episode * 54 * Avg Reward is ==> -1241.8228947430773\n",
      "Episode * 55 * Avg Reward is ==> -1242.9567269108156\n",
      "Episode * 56 * Avg Reward is ==> -1228.726632696745\n",
      "Episode * 57 * Avg Reward is ==> -1231.0592793333967\n",
      "Episode * 58 * Avg Reward is ==> -1227.6348236246627\n",
      "Episode * 59 * Avg Reward is ==> -1226.8609715865537\n",
      "Episode * 60 * Avg Reward is ==> -1211.437753059926\n",
      "Episode * 61 * Avg Reward is ==> -1209.585517058571\n",
      "Episode * 62 * Avg Reward is ==> -1214.2211983572047\n",
      "Episode * 63 * Avg Reward is ==> -1202.9938639771574\n",
      "Episode * 64 * Avg Reward is ==> -1214.2341087410925\n",
      "Episode * 65 * Avg Reward is ==> -1235.1018183253168\n",
      "Episode * 66 * Avg Reward is ==> -1240.409285787498\n",
      "Episode * 67 * Avg Reward is ==> -1229.4529585453952\n",
      "Episode * 68 * Avg Reward is ==> -1235.990575853108\n",
      "Episode * 69 * Avg Reward is ==> -1248.025170137762\n",
      "Episode * 70 * Avg Reward is ==> -1240.8079246835098\n",
      "Episode * 71 * Avg Reward is ==> -1244.2212911996419\n",
      "Episode * 72 * Avg Reward is ==> -1235.2584965474057\n",
      "Episode * 73 * Avg Reward is ==> -1257.5357543274672\n",
      "Episode * 74 * Avg Reward is ==> -1257.589198695247\n",
      "Episode * 75 * Avg Reward is ==> -1250.2419561850352\n",
      "Episode * 76 * Avg Reward is ==> -1249.6183771117478\n",
      "Episode * 77 * Avg Reward is ==> -1240.4670838802645\n",
      "Episode * 78 * Avg Reward is ==> -1231.8527573421084\n",
      "Episode * 79 * Avg Reward is ==> -1234.1192999699356\n",
      "Episode * 80 * Avg Reward is ==> -1231.2186992821441\n",
      "Episode * 81 * Avg Reward is ==> -1238.9398461614876\n",
      "Episode * 82 * Avg Reward is ==> -1242.0731393904716\n",
      "Episode * 83 * Avg Reward is ==> -1246.0031733471476\n",
      "Episode * 84 * Avg Reward is ==> -1236.8435286815698\n",
      "Episode * 85 * Avg Reward is ==> -1253.6023458903458\n",
      "Episode * 86 * Avg Reward is ==> -1255.5082609597516\n",
      "Episode * 87 * Avg Reward is ==> -1266.7513943444735\n",
      "Episode * 88 * Avg Reward is ==> -1275.8945287003887\n",
      "Episode * 89 * Avg Reward is ==> -1279.0901661422577\n",
      "Episode * 90 * Avg Reward is ==> -1287.3419545246707\n",
      "Episode * 91 * Avg Reward is ==> -1298.0922143817913\n",
      "Episode * 92 * Avg Reward is ==> -1307.157394990908\n",
      "Episode * 93 * Avg Reward is ==> -1307.5126769323463\n",
      "Episode * 94 * Avg Reward is ==> -1315.8479779535835\n",
      "Episode * 95 * Avg Reward is ==> -1302.1606539415977\n",
      "Episode * 96 * Avg Reward is ==> -1311.9590823654355\n",
      "Episode * 97 * Avg Reward is ==> -1314.392269668889\n",
      "Episode * 98 * Avg Reward is ==> -1314.1863638802527\n",
      "Episode * 99 * Avg Reward is ==> -1317.277512441421\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To store reward history of each episode\n",
    "ep_reward_list = []\n",
    "# To store average reward history of last few episodes\n",
    "avg_reward_list = []\n",
    "\n",
    "trial_times = 1\n",
    "\n",
    "for trial in range(trial_times):\n",
    "    \n",
    "    #reset the networks\n",
    "    actor_model = get_actor()\n",
    "    critic_model = get_critic()\n",
    "\n",
    "    target_actor = get_actor()\n",
    "    target_critic = get_critic()\n",
    "\n",
    "    # Making the weights equal initially\n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "    \n",
    "    # add sublists for each trial\n",
    "    avg_reward_list.append([])\n",
    "    ep_reward_list.append([])\n",
    "    \n",
    "    for ep in range(total_episodes):\n",
    "\n",
    "        prev_state = env.reset()\n",
    "        episodic_reward = 0\n",
    "\n",
    "        while True:\n",
    "            # Uncomment this to see the Actor in action\n",
    "            # But not in a python notebook.\n",
    "            # env.render()\n",
    "\n",
    "            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "            action = policy(tf_prev_state, ou_noise)\n",
    "            # Recieve state and reward from environment.\n",
    "            state, reward, done, info = env.step(action)\n",
    "\n",
    "            buffer.record((prev_state, action, reward, state))\n",
    "            episodic_reward += reward\n",
    "\n",
    "            buffer.learn()\n",
    "            update_target(target_actor.variables, actor_model.variables, tau)\n",
    "            update_target(target_critic.variables, critic_model.variables, tau)\n",
    "\n",
    "            # End this episode when `done` is True\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            prev_state = state\n",
    "\n",
    "        ep_reward_list[trial].append(episodic_reward)\n",
    "\n",
    "        # Mean of last 40 episodes\n",
    "        avg_reward = np.mean(ep_reward_list[trial][-40:])\n",
    "        print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        avg_reward_list[trial].append(avg_reward)\n",
    "\n",
    "# Plotting graph\n",
    "# Episodes versus Avg. Rewards\n",
    "for idx, p in enumerate(avg_reward_list):\n",
    "    plt.plot(p, label=str(idx))\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Epsiodic Reward (40)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f9f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "actor_model.save_weights(\"Weights/pendulum_actor.h5\")\n",
    "critic_model.save_weights(\"Weights/pendulum_critic.h5\")\n",
    "\n",
    "target_actor.save_weights(\"Weights/pendulum_target_actor.h5\")\n",
    "target_critic.save_weights(\"Weights/pendulum_target_critic.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
