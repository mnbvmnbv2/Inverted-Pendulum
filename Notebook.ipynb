{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7764110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593313f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "DeprecatedEnv",
     "evalue": "Env Pendulum-v1 not found (valid versions include ['Pendulum-v0'])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\envs\\registration.py:150\u001b[0m, in \u001b[0;36mEnvRegistry.spec\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_specs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# Parse the env name and check to see if it matches the non-version\u001b[39;00m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# part of a valid env (could also check the exact number here)\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Pendulum-v1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDeprecatedEnv\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m problem \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPendulum-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# This is needed to get the input size for the NN\u001b[39;00m\n\u001b[0;32m      5\u001b[0m num_states \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\envs\\registration.py:184\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake\u001b[39m(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m registry\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\envs\\registration.py:105\u001b[0m, in \u001b[0;36mEnvRegistry.make\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking new env: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, path)\n\u001b[1;32m--> 105\u001b[0m spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m env \u001b[38;5;241m=\u001b[39m spec\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# We used to have people override _reset/_step rather than\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# reset/step. Set _gym_disable_underscore_compat = True on\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# your environment if you use these methods and don't want\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# compatibility code to be invoked.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\envs\\registration.py:161\u001b[0m, in \u001b[0;36mEnvRegistry.spec\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    155\u001b[0m matching_envs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    156\u001b[0m     valid_env_name\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m valid_env_name, valid_env_spec \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_specs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m env_name \u001b[38;5;241m==\u001b[39m valid_env_spec\u001b[38;5;241m.\u001b[39m_env_name\n\u001b[0;32m    159\u001b[0m ]\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matching_envs:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mDeprecatedEnv(\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnv \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not found (valid versions include \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    163\u001b[0m             \u001b[38;5;28mid\u001b[39m, matching_envs\n\u001b[0;32m    164\u001b[0m         )\n\u001b[0;32m    165\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mUnregisteredEnv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo registered env with id: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mid\u001b[39m))\n",
      "\u001b[1;31mDeprecatedEnv\u001b[0m: Env Pendulum-v1 not found (valid versions include ['Pendulum-v0'])"
     ]
    }
   ],
   "source": [
    "problem = \"Pendulum-v1\"\n",
    "env = gym.make(problem)\n",
    "\n",
    "# This is needed to get the input size for the NN\n",
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "# This is needed to clip the actions within the legal boundaries\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a25ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a noise used in the paper that introduced DDPG https://arxiv.org/pdf/1509.02971v6.pdf\n",
    "# From what I understand, we can also use Gaussian or other noise without much difference,\n",
    "# I left the noise as is\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493ba423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Its important to make sure we only sample from used buffer space\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "\n",
    "    # Makes a record of the outputted (s,a,r,s') obervation tuple\n",
    "    def record(self, obs_tuple):\n",
    "        # Reuse the same buffer replacing old entries\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f235a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(layer1=400, layer2=300):\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(inputs)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    # Multiply to fill the whole action space which should be equal around 0\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_critic(layer1=400, layer2=300):\n",
    "    # State as input\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(concat)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    # Make it into a keras model\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "765aff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002,\n",
    "            actor_lr=0.001, gamma=0.99, tau=0.005):\n",
    "        \n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "        self.std_dev = std_dev\n",
    "        self.critic_lr = critic_lr\n",
    "        self.actor_lr = actor_lr\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.actor_model = get_actor(layer1=400, layer2=300)\n",
    "        self.critic_model = get_critic(layer1=400, layer2=300)\n",
    "\n",
    "        self.target_actor = get_actor(layer1=400, layer2=300)\n",
    "        self.target_critic = get_critic(layer1=400, layer2=300)\n",
    "        \n",
    "        self.critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "        \n",
    "        # Making the weights equal initially\n",
    "        self.target_actor.set_weights(self.actor_model.get_weights())\n",
    "        self.target_critic.set_weights(self.critic_model.get_weights())\n",
    "        \n",
    "        self.buffer = Buffer(buffer_capacity, batch_size)\n",
    "        \n",
    "        self.ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "    \n",
    "    # Move the update and learn function from buffer to Agent to \"decrease\" scope\n",
    "    @tf.function\n",
    "    def update(\n",
    "        self, state_batch, action_batch, reward_batch, next_state_batch,\n",
    "    ):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(next_state_batch, training=True)\n",
    "            y = reward_batch + self.gamma * self.target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = self.critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, self.critic_model.trainable_variables)\n",
    "        self.critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, self.critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = self.actor_model(state_batch, training=True)\n",
    "            critic_value = self.critic_model([state_batch, actions], training=True)\n",
    "\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, self.actor_model.trainable_variables)\n",
    "        self.actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, self.actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Sample only valid data\n",
    "        record_range = min(self.buffer.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.buffer.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.buffer.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.buffer.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.buffer.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
    "        \n",
    "    def policy(self, state, noise_object, use_noise=True):\n",
    "        # For doing actions without added noise\n",
    "        if not use_noise:     \n",
    "            sampled_actions = tf.squeeze(actor_model(state)).numpy()\n",
    "            legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "            return [np.squeeze(legal_action)]\n",
    "        else:\n",
    "            sampled_actions = tf.squeeze(self.actor_model(state))\n",
    "            noise = noise_object()\n",
    "            # Adding noise to action\n",
    "            sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "            # We make sure action is within bounds\n",
    "            legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "            return [np.squeeze(legal_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ebb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This updates the weights in a slow manner which keeps stability\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f021dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(total_trials=3, total_episodes=100):\n",
    "    # To store reward history of each episode\n",
    "    ep_reward_list = []\n",
    "    # To store average reward history of last few episodes\n",
    "    avg_reward_list = []\n",
    "    \n",
    "    for trial in range(total_trials):\n",
    "\n",
    "        # add sublists for each trial\n",
    "        avg_reward_list.append([])\n",
    "        ep_reward_list.append([])\n",
    "\n",
    "        agent = Agent(buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002,\n",
    "                actor_lr=0.001, gamma=0.99, tau=0.005)\n",
    "\n",
    "        for ep in range(total_episodes):\n",
    "\n",
    "            prev_state = env.reset()\n",
    "            episodic_reward = 0\n",
    "\n",
    "            while True:\n",
    "                tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "                action = agent.policy(tf_prev_state, agent.ou_noise)\n",
    "                # Recieve state and reward from environment.\n",
    "                state, reward, done, info = env.step(action)\n",
    "\n",
    "                agent.buffer.record((prev_state, action, reward, state))\n",
    "                episodic_reward += reward\n",
    "\n",
    "                agent.learn()\n",
    "                update_target(agent.target_actor.variables, agent.actor_model.variables, agent.tau)\n",
    "                update_target(agent.target_critic.variables, agent.critic_model.variables, agent.tau)\n",
    "\n",
    "                # End this episode if en episode is done\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                prev_state = state\n",
    "\n",
    "            ep_reward_list[trial].append(episodic_reward)\n",
    "\n",
    "            # Mean of last 40 episodes\n",
    "            avg_reward = np.mean(ep_reward_list[trial][-40:])\n",
    "            print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "            avg_reward_list[trial].append(avg_reward)\n",
    "\n",
    "    # Plotting graph\n",
    "    for idx, p in enumerate(avg_reward_list):\n",
    "        plt.plot(p, label=str(idx))\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Avg. Epsiodic Reward (40)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89a8efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Avg Reward is ==> -1456.7150368016746\n",
      "Episode * 1 * Avg Reward is ==> -1463.8021019801506\n",
      "Episode * 2 * Avg Reward is ==> -1524.2428655976962\n",
      "Episode * 3 * Avg Reward is ==> -1549.7448027472105\n",
      "Episode * 4 * Avg Reward is ==> -1556.9248211955774\n",
      "Episode * 5 * Avg Reward is ==> -1512.5953420076414\n",
      "Episode * 6 * Avg Reward is ==> -1504.9309471286494\n",
      "Episode * 7 * Avg Reward is ==> -1490.5851117549628\n",
      "Episode * 8 * Avg Reward is ==> -1425.4078258601203\n",
      "Episode * 9 * Avg Reward is ==> -1376.126714739337\n",
      "Episode * 10 * Avg Reward is ==> -1335.4688790590865\n",
      "Episode * 11 * Avg Reward is ==> -1292.2108127963809\n",
      "Episode * 12 * Avg Reward is ==> -1213.1411904579531\n",
      "Episode * 13 * Avg Reward is ==> -1147.175007931117\n",
      "Episode * 14 * Avg Reward is ==> -1079.6168746693288\n",
      "Episode * 15 * Avg Reward is ==> -1029.2663365981043\n",
      "Episode * 16 * Avg Reward is ==> -996.0353914900079\n",
      "Episode * 17 * Avg Reward is ==> -940.8629825679423\n",
      "Episode * 18 * Avg Reward is ==> -898.1130356661149\n",
      "Episode * 19 * Avg Reward is ==> -859.3056909933651\n",
      "Episode * 20 * Avg Reward is ==> -824.0730470892976\n",
      "Episode * 21 * Avg Reward is ==> -792.4676798553351\n",
      "Episode * 22 * Avg Reward is ==> -806.5194999478509\n",
      "Episode * 23 * Avg Reward is ==> -777.830662908383\n",
      "Episode * 24 * Avg Reward is ==> -760.7610187560109\n",
      "Episode * 25 * Avg Reward is ==> -745.7464111680661\n",
      "Episode * 26 * Avg Reward is ==> -722.97500336969\n",
      "Episode * 27 * Avg Reward is ==> -701.6726452448682\n",
      "Episode * 28 * Avg Reward is ==> -681.4603201374856\n",
      "Episode * 29 * Avg Reward is ==> -662.8456226074749\n",
      "Episode * 30 * Avg Reward is ==> -653.2263177481583\n",
      "Episode * 31 * Avg Reward is ==> -636.6628297833988\n",
      "Episode * 32 * Avg Reward is ==> -621.0613547829248\n",
      "Episode * 33 * Avg Reward is ==> -606.150935029837\n",
      "Episode * 34 * Avg Reward is ==> -592.3540325200977\n",
      "Episode * 35 * Avg Reward is ==> -582.93590744544\n",
      "Episode * 36 * Avg Reward is ==> -570.6482752796346\n",
      "Episode * 37 * Avg Reward is ==> -561.8991918708718\n",
      "Episode * 38 * Avg Reward is ==> -550.6938274496209\n",
      "Episode * 39 * Avg Reward is ==> -540.1764684888724\n",
      "Episode * 40 * Avg Reward is ==> -506.91834217070465\n",
      "Episode * 41 * Avg Reward is ==> -473.1506443316695\n",
      "Episode * 42 * Avg Reward is ==> -432.065621685734\n",
      "Episode * 43 * Avg Reward is ==> -394.34846633491486\n",
      "Episode * 44 * Avg Reward is ==> -354.774219604799\n",
      "Episode * 45 * Avg Reward is ==> -325.59763721848964\n",
      "Episode * 46 * Avg Reward is ==> -292.2928272545998\n",
      "Episode * 47 * Avg Reward is ==> -260.8521042226157\n",
      "Episode * 48 * Avg Reward is ==> -241.15408223778473\n",
      "Episode * 49 * Avg Reward is ==> -220.77845641942477\n",
      "Episode * 50 * Avg Reward is ==> -197.59954304576192\n",
      "Episode * 51 * Avg Reward is ==> -183.65920530604552\n",
      "Episode * 52 * Avg Reward is ==> -183.1080967093058\n",
      "Episode * 53 * Avg Reward is ==> -184.62713774647028\n",
      "Episode * 54 * Avg Reward is ==> -187.07095496205375\n",
      "Episode * 55 * Avg Reward is ==> -183.28550330157202\n",
      "Episode * 56 * Avg Reward is ==> -177.8026546330546\n",
      "Episode * 57 * Avg Reward is ==> -180.84327499282963\n",
      "Episode * 58 * Avg Reward is ==> -183.89368024012273\n",
      "Episode * 59 * Avg Reward is ==> -186.68870606533477\n",
      "Episode * 60 * Avg Reward is ==> -186.60072190412706\n",
      "Episode * 61 * Avg Reward is ==> -189.5973760355693\n",
      "Episode * 62 * Avg Reward is ==> -170.32369683154522\n",
      "Episode * 63 * Avg Reward is ==> -175.45494382827647\n",
      "Episode * 64 * Avg Reward is ==> -169.71147914720117\n",
      "Episode * 65 * Avg Reward is ==> -163.6234411291644\n",
      "Episode * 66 * Avg Reward is ==> -172.77239095409792\n",
      "Episode * 67 * Avg Reward is ==> -178.66974657644474\n",
      "Episode * 68 * Avg Reward is ==> -178.9921346766373\n",
      "Episode * 69 * Avg Reward is ==> -179.19024709278864\n",
      "Episode * 70 * Avg Reward is ==> -173.36747966762465\n",
      "Episode * 71 * Avg Reward is ==> -176.24877541770033\n",
      "Episode * 72 * Avg Reward is ==> -176.21685180100752\n",
      "Episode * 73 * Avg Reward is ==> -176.35580967120725\n",
      "Episode * 74 * Avg Reward is ==> -176.6173056409794\n",
      "Episode * 75 * Avg Reward is ==> -178.96960190565534\n",
      "Episode * 76 * Avg Reward is ==> -179.02094210530504\n",
      "Episode * 77 * Avg Reward is ==> -176.21677844936215\n",
      "Episode * 78 * Avg Reward is ==> -178.91410625226803\n",
      "Episode * 79 * Avg Reward is ==> -178.815786723473\n",
      "Episode * 80 * Avg Reward is ==> -179.00029485328832\n",
      "Episode * 81 * Avg Reward is ==> -181.82894752327292\n",
      "Episode * 82 * Avg Reward is ==> -184.8334625267739\n",
      "Episode * 83 * Avg Reward is ==> -188.16945576723487\n",
      "Episode * 84 * Avg Reward is ==> -191.3461074110167\n",
      "Episode * 85 * Avg Reward is ==> -194.40322256175608\n",
      "Episode * 86 * Avg Reward is ==> -199.23855524284983\n",
      "Episode * 87 * Avg Reward is ==> -199.08862689665176\n",
      "Episode * 88 * Avg Reward is ==> -199.34947826974604\n",
      "Episode * 89 * Avg Reward is ==> -199.48205355925546\n",
      "Episode * 90 * Avg Reward is ==> -199.49728013109524\n",
      "Episode * 91 * Avg Reward is ==> -196.03536366268912\n",
      "Episode * 92 * Avg Reward is ==> -192.9768888341484\n",
      "Episode * 93 * Avg Reward is ==> -184.27383360130682\n",
      "Episode * 94 * Avg Reward is ==> -181.46217810997\n",
      "Episode * 95 * Avg Reward is ==> -181.49907683488354\n",
      "Episode * 96 * Avg Reward is ==> -175.5425205279454\n",
      "Episode * 97 * Avg Reward is ==> -175.5613141652728\n",
      "Episode * 98 * Avg Reward is ==> -172.32498196038455\n",
      "Episode * 99 * Avg Reward is ==> -169.5424712380845\n",
      "Episode * 0 * Avg Reward is ==> -1535.0893472747819\n",
      "Episode * 1 * Avg Reward is ==> -1250.9947101674202\n",
      "Episode * 2 * Avg Reward is ==> -1305.6414008483414\n",
      "Episode * 3 * Avg Reward is ==> -1373.909256008909\n",
      "Episode * 4 * Avg Reward is ==> -1397.676152152118\n",
      "Episode * 5 * Avg Reward is ==> -1396.8598541064637\n",
      "Episode * 6 * Avg Reward is ==> -1400.7588781052498\n",
      "Episode * 7 * Avg Reward is ==> -1406.4628328425188\n",
      "Episode * 8 * Avg Reward is ==> -1413.8775018104996\n",
      "Episode * 9 * Avg Reward is ==> -1348.0023385820887\n",
      "Episode * 10 * Avg Reward is ==> -1338.8171321540906\n",
      "Episode * 11 * Avg Reward is ==> -1315.5266952812763\n",
      "Episode * 12 * Avg Reward is ==> -1293.5173890021072\n",
      "Episode * 13 * Avg Reward is ==> -1239.775749884988\n",
      "Episode * 14 * Avg Reward is ==> -1165.7428689383137\n",
      "Episode * 15 * Avg Reward is ==> -1110.194876118131\n",
      "Episode * 16 * Avg Reward is ==> -1060.2258768605445\n",
      "Episode * 17 * Avg Reward is ==> -1001.4074629548863\n",
      "Episode * 18 * Avg Reward is ==> -955.5588350572963\n",
      "Episode * 19 * Avg Reward is ==> -926.588084238512\n",
      "Episode * 20 * Avg Reward is ==> -888.5501245057594\n",
      "Episode * 21 * Avg Reward is ==> -859.7715145992624\n",
      "Episode * 22 * Avg Reward is ==> -827.8742214972365\n",
      "Episode * 23 * Avg Reward is ==> -798.3992547806016\n",
      "Episode * 24 * Avg Reward is ==> -771.6285115194534\n",
      "Episode * 25 * Avg Reward is ==> -742.0034014683363\n",
      "Episode * 26 * Avg Reward is ==> -723.5573061008108\n",
      "Episode * 27 * Avg Reward is ==> -702.1293361467444\n",
      "Episode * 28 * Avg Reward is ==> -686.4767933518243\n",
      "Episode * 29 * Avg Reward is ==> -667.7357595327886\n",
      "Episode * 30 * Avg Reward is ==> -656.7638412351868\n",
      "Episode * 31 * Avg Reward is ==> -639.9437172942551\n",
      "Episode * 32 * Avg Reward is ==> -620.646742836651\n",
      "Episode * 33 * Avg Reward is ==> -606.2171254895036\n",
      "Episode * 34 * Avg Reward is ==> -595.9196331526317\n",
      "Episode * 35 * Avg Reward is ==> -579.4154441486723\n",
      "Episode * 36 * Avg Reward is ==> -567.1339041731495\n",
      "Episode * 37 * Avg Reward is ==> -555.5114737072671\n",
      "Episode * 38 * Avg Reward is ==> -544.4552714007309\n",
      "Episode * 39 * Avg Reward is ==> -533.9672936276596\n",
      "Episode * 40 * Avg Reward is ==> -503.6774872371143\n",
      "Episode * 41 * Avg Reward is ==> -518.2102194776877\n",
      "Episode * 42 * Avg Reward is ==> -523.5993495312425\n",
      "Episode * 43 * Avg Reward is ==> -522.8213701384491\n",
      "Episode * 44 * Avg Reward is ==> -491.8474660103091\n",
      "Episode * 45 * Avg Reward is ==> -463.2008775566775\n",
      "Episode * 46 * Avg Reward is ==> -433.71713980122024\n",
      "Episode * 47 * Avg Reward is ==> -403.3069101698134\n",
      "Episode * 48 * Avg Reward is ==> -374.4019406626494\n",
      "Episode * 49 * Avg Reward is ==> -358.56521751671016\n",
      "Episode * 50 * Avg Reward is ==> -330.34355618328846\n",
      "Episode * 51 * Avg Reward is ==> -307.11693603254014\n",
      "Episode * 52 * Avg Reward is ==> -284.566899592358\n",
      "Episode * 53 * Avg Reward is ==> -282.79089704849105\n",
      "Episode * 54 * Avg Reward is ==> -282.6704621132791\n",
      "Episode * 55 * Avg Reward is ==> -278.7497846670236\n",
      "Episode * 56 * Avg Reward is ==> -278.1559094776051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 57 * Avg Reward is ==> -281.2275102837278\n",
      "Episode * 58 * Avg Reward is ==> -283.9490655421572\n",
      "Episode * 59 * Avg Reward is ==> -280.38950017439294\n",
      "Episode * 60 * Avg Reward is ==> -283.0168413478002\n",
      "Episode * 61 * Avg Reward is ==> -279.5729767934632\n",
      "Episode * 62 * Avg Reward is ==> -285.8687218300082\n",
      "Episode * 63 * Avg Reward is ==> -291.8216243736365\n",
      "Episode * 64 * Avg Reward is ==> -294.80490327893847\n",
      "Episode * 65 * Avg Reward is ==> -297.9251956450396\n",
      "Episode * 66 * Avg Reward is ==> -295.1047869147807\n",
      "Episode * 67 * Avg Reward is ==> -298.2409671167654\n",
      "Episode * 68 * Avg Reward is ==> -300.4153384644511\n",
      "Episode * 69 * Avg Reward is ==> -300.47945107628414\n",
      "Episode * 70 * Avg Reward is ==> -300.05110186974235\n",
      "Episode * 71 * Avg Reward is ==> -303.2703673080591\n",
      "Episode * 72 * Avg Reward is ==> -303.21204142392224\n",
      "Episode * 73 * Avg Reward is ==> -318.7077309862504\n",
      "Episode * 74 * Avg Reward is ==> -312.59712522648226\n",
      "Episode * 75 * Avg Reward is ==> -315.62914902364923\n",
      "Episode * 76 * Avg Reward is ==> -315.5526861257979\n",
      "Episode * 77 * Avg Reward is ==> -315.32973798858245\n",
      "Episode * 78 * Avg Reward is ==> -318.16821058923085\n",
      "Episode * 79 * Avg Reward is ==> -318.0473947534845\n",
      "Episode * 80 * Avg Reward is ==> -309.97230999675\n",
      "Episode * 81 * Avg Reward is ==> -274.2730411383837\n",
      "Episode * 82 * Avg Reward is ==> -236.56226605388656\n",
      "Episode * 83 * Avg Reward is ==> -206.6434048557131\n",
      "Episode * 84 * Avg Reward is ==> -203.3105615706577\n",
      "Episode * 85 * Avg Reward is ==> -200.34084625092459\n",
      "Episode * 86 * Avg Reward is ==> -194.28663894187463\n",
      "Episode * 87 * Avg Reward is ==> -196.2253034004554\n",
      "Episode * 88 * Avg Reward is ==> -191.17544897822705\n",
      "Episode * 89 * Avg Reward is ==> -191.16255197911715\n",
      "Episode * 90 * Avg Reward is ==> -191.39756202055423\n",
      "Episode * 91 * Avg Reward is ==> -188.18227733336434\n",
      "Episode * 92 * Avg Reward is ==> -185.03253013371597\n",
      "Episode * 93 * Avg Reward is ==> -176.29512119357642\n",
      "Episode * 94 * Avg Reward is ==> -181.7155008169497\n",
      "Episode * 95 * Avg Reward is ==> -188.06988015489583\n",
      "Episode * 96 * Avg Reward is ==> -190.00700092311453\n",
      "Episode * 97 * Avg Reward is ==> -187.04653137596517\n",
      "Episode * 98 * Avg Reward is ==> -184.26473365332086\n",
      "Episode * 99 * Avg Reward is ==> -181.40730317160182\n",
      "Episode * 0 * Avg Reward is ==> -1538.4776733868591\n",
      "Episode * 1 * Avg Reward is ==> -1491.711595918027\n",
      "Episode * 2 * Avg Reward is ==> -1561.1145843752392\n",
      "Episode * 3 * Avg Reward is ==> -1590.3450144612034\n",
      "Episode * 4 * Avg Reward is ==> -1595.7735695199692\n",
      "Episode * 5 * Avg Reward is ==> -1548.9279476753072\n",
      "Episode * 6 * Avg Reward is ==> -1547.1371103639146\n",
      "Episode * 7 * Avg Reward is ==> -1454.0441515090015\n",
      "Episode * 8 * Avg Reward is ==> -1430.5706376365767\n",
      "Episode * 9 * Avg Reward is ==> -1377.9534759985072\n",
      "Episode * 10 * Avg Reward is ==> -1390.5328853544522\n",
      "Episode * 11 * Avg Reward is ==> -1366.8043444106406\n",
      "Episode * 12 * Avg Reward is ==> -1315.1419723141457\n",
      "Episode * 13 * Avg Reward is ==> -1275.8913089433038\n",
      "Episode * 14 * Avg Reward is ==> -1235.4834759801156\n",
      "Episode * 15 * Avg Reward is ==> -1190.5981598582914\n",
      "Episode * 16 * Avg Reward is ==> -1157.2341147226098\n",
      "Episode * 17 * Avg Reward is ==> -1134.5977302490137\n",
      "Episode * 18 * Avg Reward is ==> -1107.2823071814207\n",
      "Episode * 19 * Avg Reward is ==> -1077.2600892315463\n",
      "Episode * 20 * Avg Reward is ==> -1049.795772575956\n",
      "Episode * 21 * Avg Reward is ==> -1019.090337940817\n",
      "Episode * 22 * Avg Reward is ==> -985.7151648170947\n",
      "Episode * 23 * Avg Reward is ==> -945.0638803950975\n",
      "Episode * 24 * Avg Reward is ==> -912.3801675229181\n",
      "Episode * 25 * Avg Reward is ==> -881.9565334725993\n",
      "Episode * 26 * Avg Reward is ==> -854.0382730945402\n",
      "Episode * 27 * Avg Reward is ==> -832.1207162541681\n",
      "Episode * 28 * Avg Reward is ==> -807.8712693791745\n",
      "Episode * 29 * Avg Reward is ==> -785.0693031739161\n",
      "Episode * 30 * Avg Reward is ==> -763.812640369809\n",
      "Episode * 31 * Avg Reward is ==> -743.9984838463665\n",
      "Episode * 32 * Avg Reward is ==> -725.0878988219697\n",
      "Episode * 33 * Avg Reward is ==> -707.462331380223\n",
      "Episode * 34 * Avg Reward is ==> -694.4900104059724\n",
      "Episode * 35 * Avg Reward is ==> -681.9948950280573\n",
      "Episode * 36 * Avg Reward is ==> -667.0364190959612\n",
      "Episode * 37 * Avg Reward is ==> -653.047185288383\n",
      "Episode * 38 * Avg Reward is ==> -642.8019296928047\n",
      "Episode * 39 * Avg Reward is ==> -629.9196280618955\n",
      "Episode * 40 * Avg Reward is ==> -597.5871760895764\n",
      "Episode * 41 * Avg Reward is ==> -564.7819562213225\n",
      "Episode * 42 * Avg Reward is ==> -528.8371916812987\n",
      "Episode * 43 * Avg Reward is ==> -493.02472296211135\n",
      "Episode * 44 * Avg Reward is ==> -455.9252079345482\n",
      "Episode * 45 * Avg Reward is ==> -426.53924288862635\n",
      "Episode * 46 * Avg Reward is ==> -391.40433580917534\n",
      "Episode * 47 * Avg Reward is ==> -374.57227400938655\n",
      "Episode * 48 * Avg Reward is ==> -346.51842547781723\n",
      "Episode * 49 * Avg Reward is ==> -332.9441048444746\n",
      "Episode * 50 * Avg Reward is ==> -295.14812932810736\n",
      "Episode * 51 * Avg Reward is ==> -270.69128933951094\n",
      "Episode * 52 * Avg Reward is ==> -256.29064220166885\n",
      "Episode * 53 * Avg Reward is ==> -243.07823529904272\n",
      "Episode * 54 * Avg Reward is ==> -229.60137656975394\n",
      "Episode * 55 * Avg Reward is ==> -216.77267497755466\n",
      "Episode * 56 * Avg Reward is ==> -204.1072662662829\n",
      "Episode * 57 * Avg Reward is ==> -194.16391610450347\n",
      "Episode * 58 * Avg Reward is ==> -188.05089186977855\n",
      "Episode * 59 * Avg Reward is ==> -178.6578892432141\n",
      "Episode * 60 * Avg Reward is ==> -172.34449276142726\n",
      "Episode * 61 * Avg Reward is ==> -163.06955116963718\n",
      "Episode * 62 * Avg Reward is ==> -159.895711841308\n",
      "Episode * 63 * Avg Reward is ==> -162.63206842697704\n",
      "Episode * 64 * Avg Reward is ==> -165.55000327369376\n",
      "Episode * 65 * Avg Reward is ==> -168.21715104845416\n",
      "Episode * 66 * Avg Reward is ==> -167.94299624957836\n",
      "Episode * 67 * Avg Reward is ==> -168.1166685895971\n",
      "Episode * 68 * Avg Reward is ==> -168.07543291828677\n",
      "Episode * 69 * Avg Reward is ==> -165.0539621228075\n",
      "Episode * 70 * Avg Reward is ==> -165.19602466738442\n",
      "Episode * 71 * Avg Reward is ==> -165.02334867439\n",
      "Episode * 72 * Avg Reward is ==> -164.99096847533025\n",
      "Episode * 73 * Avg Reward is ==> -165.05212503408063\n",
      "Episode * 74 * Avg Reward is ==> -161.6858898059246\n",
      "Episode * 75 * Avg Reward is ==> -161.58258101741262\n",
      "Episode * 76 * Avg Reward is ==> -161.37611989947632\n",
      "Episode * 77 * Avg Reward is ==> -164.1936084372213\n",
      "Episode * 78 * Avg Reward is ==> -167.17211540816547\n",
      "Episode * 79 * Avg Reward is ==> -166.82183479578194\n",
      "Episode * 80 * Avg Reward is ==> -163.87991407876945\n",
      "Episode * 81 * Avg Reward is ==> -160.5956452601413\n",
      "Episode * 82 * Avg Reward is ==> -154.1473040439819\n",
      "Episode * 83 * Avg Reward is ==> -150.95717495345838\n",
      "Episode * 84 * Avg Reward is ==> -150.8239203435991\n",
      "Episode * 85 * Avg Reward is ==> -153.26275373566023\n",
      "Episode * 86 * Avg Reward is ==> -156.1611646951043\n",
      "Episode * 87 * Avg Reward is ==> -158.77474252096468\n",
      "Episode * 88 * Avg Reward is ==> -155.84575606837026\n",
      "Episode * 89 * Avg Reward is ==> -149.98172896772908\n",
      "Episode * 90 * Avg Reward is ==> -150.01078327849513\n",
      "Episode * 91 * Avg Reward is ==> -153.13004815572967\n",
      "Episode * 92 * Avg Reward is ==> -153.3689304594313\n",
      "Episode * 93 * Avg Reward is ==> -150.32663597428353\n",
      "Episode * 94 * Avg Reward is ==> -150.26799316426923\n",
      "Episode * 95 * Avg Reward is ==> -153.40452850294315\n",
      "Episode * 96 * Avg Reward is ==> -150.73185703170296\n",
      "Episode * 97 * Avg Reward is ==> -148.04019771184045\n",
      "Episode * 98 * Avg Reward is ==> -142.01902865869866\n",
      "Episode * 99 * Avg Reward is ==> -141.77899176975114\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
